{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os, re, json, random, itertools, time\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "tools_path = join(os.getcwd(), 'customer_behaviour/tools')\n",
    "sys.path.insert(1, tools_path)\n",
    "import policy_evaluation as pe\n",
    "from result import Result\n",
    "from tools import save_plt_as_eps, save_plt_as_png\n",
    "import gym\n",
    "import custom_gym\n",
    "import chainer\n",
    "import chainerrl\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir_path = 'ozzy_results/dummy/2020-05-08_14-50-32'\n",
    "\n",
    "model_path = None # join(os.getcwd(), dir_path, '12288000_checkpoint', 'model.npz')\n",
    "\n",
    "sample_length = 5000\n",
    "normalize = True\n",
    "n_demos_per_expert = 1\n",
    "n_last_days = 7\n",
    "max_n_purchases_per_n_last_days = 2\n",
    "show_info = True\n",
    "show_plots = False\n",
    "save_plots = True\n",
    "cluster_comparison = False\n",
    "\n",
    "args_path = join(dir_path, 'args.txt')\n",
    "args = json.loads(open(args_path, 'r').read())\n",
    "\n",
    "info = pe.get_info(args)\n",
    "\n",
    "# Get path of model \n",
    "model_dir_path = next((d for d in [x[0] for x in os.walk(dir_path)] if d.endswith('finish')), None)\n",
    "\n",
    "os.makedirs(join(dir_path, 'figs'), exist_ok=True)\n",
    "\n",
    "ending_eps = '_normalize.eps' if normalize else '.eps'\n",
    "ending_png = '_normalize.png' if normalize else '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainerrl.misc.batch_states import batch_states\n",
    "def sample_probs_and_actions_from_policy(env, model, obs_normalizer, initial_state=None):\n",
    "    xp = np\n",
    "    phi = lambda x: x\n",
    "\n",
    "    probs = []\n",
    "    actions = []\n",
    "\n",
    "    obs = env.reset().astype('float32')  # Initial state\n",
    "\n",
    "    if initial_state is not None:\n",
    "        env.state = initial_state\n",
    "        obs = np.array(initial_state).astype('float32')\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        b_state = batch_states([obs], xp, phi)\n",
    "        \n",
    "        if obs_normalizer:\n",
    "            b_state = obs_normalizer(b_state, update=False)\n",
    "\n",
    "        with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "            action_distrib, _ = model(b_state)\n",
    "            action = chainer.cuda.to_cpu(action_distrib.sample().array)[0]\n",
    "\n",
    "        probs.append(action_distrib.all_prob.data[0][-1])\n",
    "        actions.append(action)\n",
    "        new_obs, _, done, _ = env.step(action)\n",
    "        obs = new_obs.astype('float32')\n",
    "\n",
    "    return probs, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"Verkar indikera att agenten inte använder all information den får tillgång till. [1]*100 ger mer extremt resultat --> än [0]*100 eftersom den inte 'ser' hela sekvensen. \""
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "\n",
    "def get_probs_for_buys(args, model_dir_path, expert=1, init='ones', dummi=True):\n",
    "    env, model, obs_normalizer = pe.get_env_and_model(args, model_dir_path, sample_length, model_path=model_path)\n",
    "    n_input_neurons = model.pi.model.in_size\n",
    "    dummy = [0]*args['n_experts']\n",
    "    if dummi:\n",
    "        dummy[expert] = 1\n",
    "    expert_trajectories = env.generate_expert_trajectories(out_dir=None, n_demos_per_expert=1, n_expert_time_steps=sample_length)\n",
    "    expert_states = expert_trajectories['states']\n",
    "    expert_actions = expert_trajectories['actions']\n",
    "    e_actions = expert_actions[expert]\n",
    "    e_states = expert_states[expert]\n",
    "    if init == 'expert':\n",
    "        index = np.random.randint(len(e_states))\n",
    "        initial_state = e_states[index].tolist()\n",
    "    elif init == 'ones':\n",
    "        initial_state = dummy + [1]*(n_input_neurons-args['n_experts'])\n",
    "    elif init == 'zeros':\n",
    "        initial_state = dummy + [0]*(n_input_neurons-args['n_experts'])\n",
    "    elif init == 'rand':\n",
    "        from customer_behaviour.tools.dgm import DGM\n",
    "        dgm = DGM()\n",
    "        #dgm.spawn_new_customer(np.random.randint(11,100))\n",
    "        dgm.spawn_new_customer(12)\n",
    "        sample = dgm.sample((n_input_neurons-args['n_experts']))\n",
    "        sample = np.sum(sample, axis=0)\n",
    "        initial_state = np.concatenate((dummy,sample))\n",
    "    probs, actions = sample_probs_and_actions_from_policy(env, model, obs_normalizer, initial_state=initial_state)\n",
    "    return probs, actions, e_actions, expert_actions\n",
    "\n",
    "probs, actions, e_actions, all_expert_actions = get_probs_for_buys(args, model_dir_path, expert=1, init='expert', dummi=False)\n",
    "#plt.plot(probs)\n",
    "#x1,x2,y1,y2 = plt.axis()\n",
    "#plt.axis((x1,x2,0,1))\n",
    "#plt.show()\n",
    "\n",
    "\"\"\"Verkar indikera att agenten inte använder all information den får tillgång till. [1]*100 ger mer extremt resultat --> än [0]*100 eftersom den inte 'ser' hela sekvensen. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.13857142857142857\n0.1362857142857143\n"
    }
   ],
   "source": [
    "def get_purchase_ratio(sequence):\n",
    "    if len(sequence) == 0:\n",
    "        return np.count_nonzero(sequence)/1\n",
    "    else: \n",
    "        seq=sequence[int(0.3*len(sequence)):]\n",
    "        return np.count_nonzero(seq)/len(seq)\n",
    "\n",
    "purchase_ratios = [get_purchase_ratio(actions[:i]) for i in range(len(actions))]\n",
    "e_purchase_ratios = [get_purchase_ratio(e_actions[:i]) for i in range(len(e_actions))]\n",
    "print(purchase_ratios[-1])\n",
    "print(e_purchase_ratios[-1])\n",
    "\n",
    "#temp = []\n",
    "#for e in range(len(all_expert_actions)):\n",
    "#    temp.append([get_purchase_ratio(all_expert_actions[e][:i]) for i in range(len(all_expert_actions[e]))])\n",
    "\n",
    "#temp = np.array(temp)\n",
    "#mean_purchase_ratio = np.mean(temp, axis=0)    \n",
    "\n",
    "#cut_off = 300\n",
    "#y = purchase_ratios[cut_off:]\n",
    "#e_y = e_purchase_ratios[cut_off:]\n",
    "#mean = mean_purchase_ratio[cut_off:]\n",
    "#fig = plt.figure()\n",
    "#plt.plot(range(cut_off, len(y) + cut_off), y, label='Agent')\n",
    "#plt.plot(range(cut_off, len(e_y) + cut_off), e_y, label='Expert 2')\n",
    "#plt.plot(range(cut_off, len(mean) + cut_off), mean, label='Average expert')\n",
    "#plt.legend()\n",
    "#plt.grid()\n",
    "#plt.ylabel('Purchase ratio')\n",
    "#plt.xlabel('Days')\n",
    "#plt.title('GAIL')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros, dummy=true\n",
    "rand, dummy=False\n",
    "expertstate, dummy=false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_behaviour.tools.tools import save_plt_as_eps\n",
    "save_plt_as_eps(fig, os.getcwd() + '/zeros_dummy.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    n_runs = 100\n",
    "    for _ in range(n_runs):\n",
    "        probs, actions, e_actions, all_expert_actions = get_probs_for_buys(args, model_dir_path, expert=2, init='zeros', dummi=True)\n",
    "        purchase_ratios = [get_purchase_ratio(actions[:i]) for i in range(len(actions))]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitvenvvenv2eaf8ab48b2844c2b04e614f77512bbb",
   "display_name": "Python 3.7.6 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}